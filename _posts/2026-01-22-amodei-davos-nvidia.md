---
layout: post
title: "Dario Amodei came to Davos to lob a grenade"
date: 2026-01-22
last_modified_at: 2026-01-22
author: "Andraž Tavčar"
category: Technology
kicker: "The Davos Standoff"
description: "At Davos, Anthropic's chief executive compared Nvidia's chip sales to China to nuclear proliferation - weeks after taking billions from the company. Inside his head, the logic apparently makes sense."
image: https://res.cloudinary.com/dvyhebi2q/image/upload/the-adriatic/2026/01/2026-01-22-amodei-davos-nvidia/hero.webp
image_caption: "Lobbing a grenade at Davos, in the style of Geist."
image_credit: ""
---

At Anthropic, one of the world's most valuable artificial intelligence companies, some engineers have stopped writing code. They describe their work to their CEO, review what the AI produces, and edit the output. The humans have become supervisors of a process they once performed.

Dario Amodei shared this detail almost casually during a panel at the World Economic Forum in Davos on Tuesday, as if it were merely an interesting data point rather than a glimpse of a transformation already underway inside his own company. But the Anthropic chief executive had not come to Switzerland to discuss workplace reorganisation.

Asked about the US administration's recent decision to [<mark class="rose">approve the sale of Nvidia's H200 chips to China</mark>](https://finance.yahoo.com/news/anthropic-ceo-stuns-davos-nvidia-013958947.html), Amodei called the move "crazy" and likened it to "selling nuclear weapons to North Korea." The remark was striking for several reasons, not least that Nvidia (the chipmaker whose products power virtually all advanced AI systems, including Anthropic's) announced just two months ago that it would invest up to $10 billion in Amodei's company. The two firms also unveiled a "deep technology partnership" at the time, complete with promises of mutual optimisation.

At Davos, Amodei compared his new partner to an arms dealer.

<figure>
  <img src="https://res.cloudinary.com/dvyhebi2q/image/upload/the-adriatic/2026/01/2026-01-22-amodei-davos-nvidia/inline.webp" alt="Dario Amodei at Davos 2026">
  <figcaption>The Day After AGI session with Dario Amodei, Chief Executive Officer and Co-Founder, Anthropic. | World Economic Forum</figcaption>
</figure>

## Why chips matter

For readers unfamiliar with the architecture of the AI industry, a brief explanation: training a powerful AI model requires enormous computational resources, and the specialised processors that provide this capacity are manufactured by a handful of companies. Nvidia dominates the market. Its chips are the bottleneck. Whoever controls their distribution shapes the pace at which AI advances globally.

The United States has spent recent years trying to [<mark class="yellow">restrict China's access</mark>](https://siliconangle.com/2026/01/20/anthropic-boss-dario-amodei-slams-trump-crazy-decision-sell-advanced-ai-chips-china/) to the most advanced semiconductors, viewing AI supremacy as a matter of national security. Last week, the administration reversed an earlier ban and approved the sale of Nvidia's H200 chips to certain Chinese customers. The chips are not Nvidia's most powerful, but they are high-performance processors capable of training sophisticated AI systems.

Amodei's position is that this decision is "a big mistake" with "incredible national security implications." His logic runs as follows: if the US can slow China's AI development by restricting chip access, it buys time to handle the technology responsibly. Without geopolitical competitors racing at the same pace, the real contest would be between companies like Anthropic and Google's DeepMind. They would still be rivals, certainly, but ones that might coordinate more easily than nation-states. [<mark class="green">Restricting chip exports</mark>](https://www.euronews.com/next/2026/01/20/ai-at-davos-2026-from-work-to-useful-and-safe-ai-heres-what-the-tech-leaders-have-said), he argued, is "one of the biggest things we can do to make sure we have time to handle this."

## The company in question

Anthropic occupies a peculiar position in the AI landscape. Founded in 2021 by former OpenAI researchers (including Amodei and his sister Daniela, who serves as president), the company markets itself as the safety-focused alternative to its competitors. "Since the beginning, Anthropic has thought in terms of [<mark>safety and reliability of AI systems</mark>](https://www.cnbc.com/2026/01/21/openai-anthropic-enterprise-davos.html)," Amodei told CNBC at Davos, adding that this focus proved "very synergistic with working with enterprises." Its flagship product, the AI assistant Claude, has earned a reputation among developers as a particularly capable tool for complex programming tasks. Speculation about a potential initial public offering has intensified in recent months, and Amodei fielded questions on the topic at Davos without committing to a timeline.

The company's growth has been extraordinary. Amodei told the Davos audience that Anthropic's revenue had increased a hundredfold in three years: from negligible sums to roughly $100 million in 2023, then $1 billion in 2024, and a projected $10 billion in 2025. For context, OpenAI reportedly earned around $20 billion in the same period. Anthropic is valued in the hundreds of billions of dollars, backed by Amazon, Google, and now Nvidia.

This financial success sits uneasily alongside Amodei's rhetoric about existential risk. He is not a man who soft-pedals his concerns. He has written publicly about the possibility that [<mark class="rose">advanced AI could pose catastrophic dangers</mark>](https://darioamodei.com/machines-of-loving-grace) to humanity. At Davos, he spoke of humanity navigating a "technological adolescence" and questioned whether we would survive it.

The tension is not lost on observers: Amodei believes he may be building something that could go terribly wrong, and he is building it as fast as anyone.

## The jobs question

Amodei's predictions for the labour market are similarly stark. He told the Davos panel that [<mark class="yellow">half of all entry-level white-collar jobs</mark>](https://eu.36kr.com/en/p/3648851352018565) could disappear within one to five years. The effects are not yet dramatic, he acknowledged, but he is already seeing shifts in software development. This is the same field where his own engineers have reportedly ceded the act of writing code to the systems they oversee. More dramatically, he suggested that AI could handle "almost all the work of software engineers end-to-end" within six to twelve months.

Demis Hassabis, chief executive of Google DeepMind, appeared alongside Amodei and offered a more measured view. He expected "new, more meaningful jobs" to emerge, and suggested that young people would be "compensated by the amazing tools out there for everyone." But he conceded that the arrival of artificial general intelligence (systems matching or exceeding human cognitive abilities) would mark the beginning of "uncharted territory."

On timelines, the two executives diverged slightly. Amodei holds to his prediction that AI models will reach "Nobel-level" performance across multiple disciplines by 2026 or 2027. Hassabis sees a 50 per cent chance of reaching that threshold by the end of the decade.

Either way, the window is short.

## What the outburst reveals

Perhaps the most remarkable aspect of Amodei's Nvidia comments is that he made them at all. Corporate executives do not typically compare their major investors and partners to arms dealers, certainly not on stage at the world's most prominent business gathering. The usual constraints (investor relations, diplomatic caution, strategic ambiguity) appear not to apply.

One interpretation is that Amodei simply got carried away with his own rhetoric, an unguarded moment in front of a receptive audience. Another is that Anthropic's position is now strong enough that he feels insulated from the consequences. The company has raised billions, its technology is in demand, and its valuation reflects a market convinced that AI is the defining industry of the coming decades.

But there is a third possibility: that Amodei genuinely believes the stakes are high enough to warrant burning bridges. If you think advanced AI could threaten human civilisation, and that chip exports to a geopolitical rival are accelerating that risk, politeness may seem like a secondary concern.

At Davos, the man building one of the world's most powerful AI systems suggested that Washington is giving away the keys. Whether anyone in Washington is listening remains unclear.
